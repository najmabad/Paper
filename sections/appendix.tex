\providecommand{\main}{..}
\documentclass[\main/main.tex]{subfiles}

\begin{document}

\appendix
\chapter{Appendix}

\tocless\section{Iterative approximation for the $m^{th}$ moments of lifetime rewards}\label{sec:recursive_moment}
\tocless\subsection{Derivation of the first moment}

The following reasoning explains the main results of Caswell's derivation. For the original explanation, see \cite{Caswell2011}.\\

Consider an individual who is in state $i$ at time $t$ and has still $t$ steps ahead until $T$.
Assume that the individual makes a transition from state $i$ to state $j$, thus gaining a reward $r_{ij}$. After this transition, the individual will find herself in state $j$ and with $t-1$ steps remaining.\\



\begin{figure}[H]
\centering
\begin{tikzpicture}
% draw horizontal line   
\draw (-0.5,0) -- (12,0);
% draw vertical lines
\foreach \x in {0,2,4,6,8,10,12}
\draw (\x cm,3pt) -- (\x cm,-3pt);
% draw nodes
\draw (12,0) node[below=3pt] {\small $t= 0$} node[above=3pt] {$   $};
\draw (4,0) node[above=17pt] (1) {$X_t = i$} node[above=3pt] {};
\draw (2,0) node[above=17pt] {} node[above=3pt] {};
\draw (6,0) node[above=17pt]  (4) {$X_{t-1}=j$} node[above=3pt] {};

\draw (8,0) node[above=17pt] {} node[above=3pt] {};
\draw (10,0) node[above=17pt] {} node[above=3pt] {};
\draw (12,0) node[above=17pt] {$T$} node[above=3pt] {};
\draw (10,0) node[below=3pt] { \small $t= 1$} node[above=3pt] {};
\draw (4,0) node[below=3pt] {\small $t = 4$} node[above=3pt] {};
\draw (6,0) node[below=3pt] {\small $t= 3$} node[above=3pt] {$  $};
\draw (5,2) node[below=3pt] {\small $r_{ij}$} node[above=3pt] {$  $};
\draw (8,0) node[below=3pt] {$t=2$} node[above=3pt] {$  $};
\draw [->] (1) to [out=30,in=150] (4) ;
\end{tikzpicture}
\caption{First moment of lifetime rewards}
\label{fig:}
\end{figure}

We can compute the first moment of lifetime accumulated rewards for such individual who starts in state $i$, conditioned on the fact that she moves from $i$ to $j$:
    \begin{equation}
        \mathds{E}[ \rho_i(t) | i \rightarrow j] = \mathds{E}[ r_{ij} + \rho_j(t-1) ]
    \end{equation}

In other words, the expected total rewards at time $t$, for an individual that starts from state $i$ and ends in any state $j$, can be thought as the reward $r_{ij}$ that she gains while moving from state $i$ to state $j$ plus the expected gain she could gain at time $t-1$ if she started in state $j$. Since $j$ is unknown, we sum over each possible state $j = 1,2, ...N$, including state $i$.
    
    
From the conditional expectation, we can retrieve the unconditional one using the law of iterated expectations and the fact that we are dealing with a partition of the sample space. The law of iterated expectations states the following \lq\lq Let X be a random variable with sample space $\Omega$. If the events $F_1, F_2, ..., F_n$ form a partition of the sample space, i.e $F_i \cap F_j = \emptyset \; \text{for} \; i \neq j$ and $\cup_i F_i = \Omega$, then:
\begin{equation}
\mathds{E} (X) = \sum_j \mathds{E}(X | F_j) P(F_j)
\end{equation}
see \cite{Grinstead1997} for a proof and an example.\\



\noindent In our notation, the unconditional expectation of $ \rho_i(t) $ becomes:
    \begin{equation}\label{unconditional}
    \begin{split}
         \mathds{E}[ \rho_i(t)] &= \sum_{j=1}^N \mathds{E}[\rho_i(t) | i \rightarrow j] \; \mathds{P}( i \rightarrow j) = \\
         &= \sum_{j=1}^N  \mathds{E}[\rho_i(t) | i \rightarrow j]\; p_{ij} =\\
         &= \sum_{j=1}^N    \mathds{E}[ r_{ij} + \rho_j(t-1)]  p_{ij} = \\
         &= \sum_{j=1}^N  \{  \mathds{E}[ r_{ij}] + \mathds{E}[\rho_j(t-1)]\}  p_{ij}
    \end{split}
    \end{equation}
in matrix form, this becomes \citep{Caswell2011}:
\begin{equation}
        \bm{\rho}^1(t+1) = (\mathbf{P} \circ \mathbf{R}^1) \mathbf{1} + \mathbf{P}^T \bm{\rho}^1(t) \;\;\;\; t=0,..., T-1
\end{equation}
where $\circ$ represents the Hadamard (or element-by-element) product, $\mathbf{1}$ is a vector of ones and $\bm{\rho}^1(0) = 0$ is the initial condition.\\

To give an intuition, imagine to have a very simple Markov process with two states $S=\{1,2\}$: the individual can start either in state 1 or 2 and then move to state 1 or 2. In order to compute the first moment, start by defining the vector $ \bm{\rho}^{k}$:
\begin{equation}
 \bm{\rho}^{(1)} (t)=
\begin{pmatrix}
\mathds{E}[\rho^1_1]\\
\mathds{E}[\rho^1_2]\\
\end{pmatrix}
\end{equation}
and the matrix $\mathbf{R}^k$:
\begin{equation}
 \bm{R}^{(1)} =
\begin{pmatrix}
\mathds{E}[r_{11}] & \mathds{E}[r_{21}]\\
\mathds{E}[r_{12}] & \mathds{E}[r_{22}]\\
\end{pmatrix}
\end{equation}

\noindent Using the formula \ref{unconditional}, the expectation of rewards for an individual who starts in state 1 will be:

\begin{equation}
\begin{split}
  \mathds{E}[\rho_1(t+1)] &= \sum_{j=1}^2 p_{1j}\{ \mathds{E}[r_{1j}] + \mathds{E}[\rho_j(t)] \}=  \\
  &= p_{11}\{ \mathds{E}[r_{11}] + \mathds{E}[\rho_1(t)] \} + p_{12}\{ \mathds{E}[r_{12}] + \mathds{E}[\rho_2(t)] \}
\end{split}
\end{equation}
Intuitively, the expectation of rewards of a Markov process that starts in state 1 is a weighted average, with weights given by the transition probabilities. Indeed, if the process remains in state 1, it is expected to gain $\mathds{E}[r_{11}]$ plus $\mathds{E}[\rho_1(t)] $, i.e. the rewards that still have to be accumulated at time $t$, given that the process will be in state 1. Similarly, if the process moves to state 2, it is expected to gain $\mathds{E}[r_{12}]$ plus $\mathds{E}[\rho_2(t)] $, i.e. the rewards that still have to be accumulated at time $t$, given that the process will be in state 2.

Using matrix notation, we are able to retrieve $\bm{\rho}(t+1)$, i.e. the vector of rewards that have to be accumulated at time $t+1$:
\begin{equation}
\setlength{\jot}{10pt}
\begin{split}
    \bm{\rho}^1(t+1) &=       
\begin{bmatrix}
      \mathds{E}[\rho_1^1(t+1)]\\
      \mathds{E}[\rho_2^1(t+1)]\\
\end{bmatrix}= \\
  &= 
 \begin{bmatrix} 
 p_{11} \big\{ \mathds{E}[r_{11}]  + \mathds{E}[\rho_1^1(t)]\big\} + p_{12}\big\{ \mathds{E}[r_{12}]  + \mathds{E}[\rho_2^1(t)]\big\}\\
  p_{21} \big\{ \mathds{E}[r_{21}]  + \mathds{E}[\rho_1^1(t)]\big\} + p_{22}\big\{ \mathds{E}[r_{22}]  + \mathds{E}[\rho_2^1(t)]\big\} \\
 \end{bmatrix} =\\
  &=  
 \begin{bmatrix} 
 p_{11}\mathds{E}[r_{11}]  +  p_{12}\mathds{E}[r_{12}] + p_{11}\mathds{E}[\rho_1^1(t)] + p_{12}\mathds{E}[\rho_2^1(t)]\\
 p_{21}\mathds{E}[r_{21}] + 
 p_{22} \mathds{E}[r_{22}] + p_{21}\mathds{E}[\rho_1^1(t)] + 
 p_{22}\mathds{E}[\rho_2^1(t)]\\
 \end{bmatrix} =\\
  &=  
 \begin{bmatrix} 
 p_{11}\mathds{E}[r_{11}]  +  p_{12}\mathds{E}[r_{12}]\\
 p_{21}\mathds{E}[r_{21}] + 
 p_{22} \mathds{E}[r_{22}]\\
 \end{bmatrix}
 + 
 \begin{bmatrix} 
 p_{11}\mathds{E}[\rho_1^1(t)] + p_{12}\mathds{E}[\rho_2^1(t)] \\
 p_{21}\mathds{E}[\rho_1^1(t)] + 
 p_{22}\mathds{E}[\rho_2^1(t)]\\
 \end{bmatrix} =\\
  &= 
 \begin{bmatrix} 
 p_{11}\mathds{E}[r_{11}] & p_{12}\mathds{E}[r_{12}]\\
 p_{21}\mathds{E}[r_{21}] & 
 p_{22} \mathds{E}[r_{22}]\\
 \end{bmatrix}
  \begin{bmatrix}
 1\\
 1\\
 \end{bmatrix}
 + 
 \begin{bmatrix} 
 p_{11}\mathds{E}[\rho_1^1(t)] + p_{12}\mathds{E}[\rho_2^1(t)] \\
 p_{21}\mathds{E}[\rho_1^1(t)] + 
 p_{22}\mathds{E}[\rho_2^1(t)]\\
 \end{bmatrix} =\\
 &= \Bigg( \begin{bmatrix} 
 p_{11}\mathds{E}[r_{11}] & p_{21}\mathds{E}[r_{21}\\
 p_{12}\mathds{E}[r_{12}]&  p_{22} \mathds{E}[r_{22}]\\
 \end{bmatrix}
  \Bigg) ^T
  \begin{bmatrix}
 1\\
 1\\
 \end{bmatrix}
 + 
 \begin{bmatrix} 
 p_{11}\mathds{E}[\rho_1^1(t)] + p_{12}\mathds{E}[\rho_2^1(t)] \\
 p_{21}\mathds{E}[\rho_1^1(t)] + 
 p_{22}\mathds{E}[\rho_2^1(t)]\\
 \end{bmatrix} =\\
 &= \Bigg(
\begin{bmatrix} 
 p_{11}& p_{21}\\
 p_{12}& p_{22}\\
 \end{bmatrix} \circ
 \begin{bmatrix} 
 \mathds{E}[r_{11}] &  \mathds{E}[r_{21}] \\
 \mathds{E}[r_{12}] &  \mathds{E}[r_{22}] \\
 \end{bmatrix}
 \Bigg) ^T
 \begin{bmatrix}
 1\\
 1\\
 \end{bmatrix}
 + 
 \begin{bmatrix} 
 p_{11}& p_{12}\\
 p_{21}& p_{22}\\
 \end{bmatrix}
 \begin{bmatrix}
      \mathds{E}[\rho_1^1(t)]\\
      \mathds{E}[\rho_2^1(t)]\\
\end{bmatrix}= \\
&= (\mathbf{P} \circ \mathbf{R}^1)^T \mathbf{1} + \mathbf{P}^T \bm{\rho}^1(t) \\
\end{split}
\end{equation}


\tocless\subsection{Derivation of the second moment}
The conditional second moment $\bm{\rho}^2(t)$ of an individual in stage $i$, given a transition from $i$ to $j$, is given by: 
\begin{equation}
\begin{split}
    \mathds{E} [\bm{\rho}_i^2 (t+1) | i \rightarrow j ] &= \mathds{E} \big\{ [ r_{ij} + \rho_j(t)]^2 \big\} =\\
    &= \mathds{E} \big\{ [ r_{ij}^2 + \rho_j(t)^2 + 2 r_{ij} \rho_j(t)] \big\} =\\
     &= \mathds{E} [ r_{ij}^2] +\mathds{E} [ \rho_j(t)^2] + 2 \mathds{E} [r_{ij}] \mathds{E} [\rho_j(t)]  =
\end{split}
\end{equation}
since $r_{ij}$ and $\rho_j(t)$ are modelled as being independent.\\

\noindent The unconditional second moment is given by: 
\begin{equation}
\begin{split}
\mathds{E} [\bm{\rho}_i^2 (t+1)] &= \sum_{j=1}^N \mathds{E} [\bm{\rho}_i^2 (t+1) | i \rightarrow j ] \mathds{P}(i\rightarrow j) =\\
&= \sum_{j=1}^N \mathds{E} [\bm{\rho}_i^2 (t+1) | i \rightarrow j ] p_{ij} =\\
&= \sum_{j=1}^N p_{ij} \{ \mathds{E} [ r_{ij}^2] +\mathds{E} [ \rho_j^2(t)] + 2 \mathds{E} [r_{ij}] \mathds{E} [\rho_j(t)]\}
\end{split}
\end{equation}

Using again the example of a very simple Markov process with two states $S=\{1,2\}$, we have:
\begin{equation}
\setlength{\jot}{10pt}
\begin{split}
    &\bm{\rho}^2(t+1) =    
\begin{bmatrix}
      \mathds{E}[\rho_1^2(t+1)]\\
      \mathds{E}[\rho_2^2(t+1)]\\
\end{bmatrix}= \\
  &= 
 \begin{bmatrix} 
 p_{11} \big\{ \mathds{E}[r^2_{11}]  + \mathds{E}[\rho_1^2(t)] + 2\mathds{E}[r_{11}]\mathds{E}[\rho_1^1(t)]  \big\} + 
 p_{12}\big\{ \mathds{E}[r^2_{12}]  + \mathds{E}[\rho_2^2(t)]+ 2\mathds{E}[r_{12}]\mathds{E}[\rho_2^1(t)] \big\} \\
  p_{21} \big\{ \mathds{E}[r^2_{21}]  + \mathds{E}[\rho_1^2(t)] + 2\mathds{E}[r_{21}]\mathds{E}[\rho_1^1(t)] \big\} +
  p_{22}\big\{ \mathds{E}[r^2_{22}]  + \mathds{E}[\rho_2^2(t)]+ 2\mathds{E}[r_{22}]\mathds{E}[\rho_2^1(t)]  \big\} \\
 \end{bmatrix} =\\
  &=  
 \begin{bmatrix} 
 p_{11}\mathds{E}[r^2_{11}]  +  p_{12}\mathds{E}[r^2_{12}] + 2p_{11}\mathds{E}[r_{11}]\mathds{E}[\rho_1^1(t)] + 2p_{12}\mathds{E}[r_{12}]\mathds{E}[\rho_2^1(t)] +  p_{11}\mathds{E}[\rho_1^2(t)] +  p_{12}\mathds{E}[\rho_2^2(t)]\\
 p_{21}\mathds{E}[r^2_{21}]  +  p_{22}\mathds{E}[r^2_{22}] + 2p_{21}\mathds{E}[r_{21}]\mathds{E}[\rho_1^1(t)] + 2p_{22}\mathds{E}[r_{22}]\mathds{E}[\rho_2^1(t)] +  p_{21}\mathds{E}[\rho_1^2(t)] +  p_{22}\mathds{E}[\rho_2^2(t)]\\
 \end{bmatrix} =\\
  &=  
 \begin{bmatrix} 
 p_{11}\mathds{E}[r^2_{11}]  +  p_{12}\mathds{E}[r^2_{12}]\\
 p_{21}\mathds{E}[r^2_{21}] + p_{22} \mathds{E}[r^2_{22}]\\
 \end{bmatrix}
 + 2
 \begin{bmatrix} 
 p_{11}\mathds{E}[r_{11}] \mathds{E}[\rho_1^1(t)] +  p_{12}\mathds{E}[r_{12}]\mathds{E}[\rho_2^1(t)]\\
 p_{21}\mathds{E}[r_{21}] \mathds{E}[\rho_1^1(t)] +  p_{22}\mathds{E}[r_{22}]\mathds{E}[\rho_2^1(t)]\\
 \end{bmatrix}
 +
 \begin{bmatrix} 
 p_{11}\mathds{E}[\rho_1^2(t)] + p_{12}\mathds{E}[\rho_2^2(t)] \\
 p_{21}\mathds{E}[\rho_1^2(t)] +  p_{22}\mathds{E}[\rho_2^2(t)]\\
 \end{bmatrix} =\\
  &= 
 \begin{bmatrix} 
 p_{11}\mathds{E}[r^2_{11}] & p_{12}\mathds{E}[r^2_{12}]\\
 p_{21}\mathds{E}[r^2_{21}] &  p_{22} \mathds{E}[r^2_{22}]\\
 \end{bmatrix}
  \begin{bmatrix}
 1\\
 1\\
 \end{bmatrix}
 + 2
 \begin{bmatrix}
 p_{11}\mathds{E}[r_{11}] & p_{12}\mathds{E}[r_{12}]\\
 p_{21}\mathds{E}[r_{21}] & p_{22}\mathds{E}[r_{22}]\\
 \end{bmatrix}
 \begin{bmatrix}
 \mathds{E}[\rho_1^1(t)]\\
 \mathds{E}[\rho_2^1(t)]\\
 \end{bmatrix}
 +
 \begin{bmatrix} 
 p_{11}& p_{12} \\
  p_{21}& p_{22} \\
 \end{bmatrix}
 \begin{bmatrix}
 \mathds{E}[\rho_2^1(t)]\\
 \mathds{E}[\rho_2^2(t)]
 \end{bmatrix}
 =
 \\
 &= \Bigg( \begin{bmatrix} 
 p_{11}\mathds{E}[r^2_{11}] & p_{21}\mathds{E}[r^2_{21}\\
 p_{12}\mathds{E}[r^2_{12}]&  p_{22} \mathds{E}[r^2_{22}]\\
 \end{bmatrix}
  \Bigg) ^T
  \begin{bmatrix}
 1\\
 1\\
 \end{bmatrix}
 + 2\Bigg( 
 \begin{bmatrix}
 p_{11}\mathds{E}[r_{11}] & p_{21}\mathds{E}[r_{21}]\\
 p_{12}\mathds{E}[r_{12}] & p_{22}\mathds{E}[r_{22}]\\
 \end{bmatrix} \Bigg) ^T
 \begin{bmatrix}
 \mathds{E}[\rho_1^1(t)]\\
 \mathds{E}[\rho_2^1(t)]\\
 \end{bmatrix}
 +\mathbf{P} ^T
 \bm{\rho}^2(t)=
 \\
 &= \Bigg( \begin{bmatrix} 
 p_{11} & p_{21}\\
 p_{12}&  p_{22} \\
 \end{bmatrix}\circ
 \begin{bmatrix}
 \mathds{E}[r^2_{11}] &\mathds{E}[r^2_{21}\\
 \mathds{E}[r^2_{12}] &\mathds{E}[r^2_{22}]\\
 \end{bmatrix}
  \Bigg) ^T
  \begin{bmatrix}
 1\\
 1\\
 \end{bmatrix}
 + 2\Bigg( 
 \begin{bmatrix}
 p_{11} & p_{21}\\
 p_{12}& p_{22}\\
 \end{bmatrix}
 \circ
 \begin{bmatrix}
 \mathds{E}[r_{11}] & \mathds{E}[r_{21}]\\
 \mathds{E}[r_{12}] & \mathds{E}[r_{22}]
 \end{bmatrix}\Bigg) ^T
 \bm{\rho}^1(t)
 +\mathbf{P}^T \bm{\rho}^2(t)=
 \\
 &=
 (  \mathbf{P} \circ \mathbf{R}^2 ) ^T +
 2 (\mathbf{P} \circ \mathbf{R}^1) ^T \bm{\rho}^1(t)+
 +\mathbf{P}^T \bm{\rho}^2(t)=
 \end{split}
\end{equation}




\tocless\subsection{Derivation of the third moment}

The same reasoning can be applied to the third moment, which is equal to:
\begin{equation}
     \bm{\rho}^3(t+1) = (\mathbf{P} \circ \mathbf{R}^3) ^ T\mathbf{1} + 3 (\mathbf{P} \circ \mathbf{R}^2) ^T \bm{\rho}^1(t) + 3 (\mathbf{P} \circ \mathbf{R}^1) ^T \bm{\rho}^2(t) + \mathbf{P}^T \bm{\rho}^3(t)
\end{equation}



\tocless\subsection{Derivation of the $m^{th}$ moment}

Summarising the above results, we have that the first, second, and third moments of lifetime rewards are given by:
\begin{equation}
    \begin{split}
     \bm{\rho}^1(t+1) &= (\mathbf{P} \circ \mathbf{R}^1) ^T\mathbf{1} + \mathbf{P}^T \bm{\rho}^1(t) \\
      \bm{\rho}^2(t+1) &= (\mathbf{P} \circ \mathbf{R}^2) ^ T\mathbf{1} + 2 (\mathbf{P} \circ \mathbf{R}^1) ^T \bm{\rho}^1(t) + 
      \mathbf{P}^T \bm{\rho}^2(t) \\
     \bm{\rho}^3(t+1) &= (\mathbf{P} \circ \mathbf{R}^3) ^ T\mathbf{1} + 3 (\mathbf{P} \circ \mathbf{R}^2) ^T \bm{\rho}^1(t) + 3 (\mathbf{P} \circ \mathbf{R}^1) ^T \bm{\rho}^2(t) + \mathbf{P}^T \bm{\rho}^3(t) \\
\end{split}
\end{equation}for $t=0, ... ,T$ and with $\bm{\rho}^1(0) = 0, \bm{\rho}^2(0) = 0,\bm{\rho}^3(0) = 0$.\\
Generalising, this is equal to:
\begin{equation}\label{recursive}
    \bm{\rho}^m(t+1) = \sum_{k=0}^{m} {m \choose k} (\mathbf{P} \circ \mathbf{R}^{m-k}) ^ T \bm{\rho}^k(t) \;\; \; m=1,2,...
\end{equation}
with $\bm{\rho}^m(0)=0$ which is exactly the formula mentioned in section \ref{sec:backward_solution}.\\


\tocless\section{Analytic solution for the $m^{th}$ moment of lifetime rewards}\label{sec:analytical_solution}

\cite{VanDaalen2017} provide the formula for the analytical solution of the $m^{th}$ moment of lifetime rewards. The original proof can be found in the appendix of their paper. The following computation expands the algebra behind the main results.\\

From the recursive formula \ref{recursive}, one can find the analytical solution solving for the equilibrium of the iterative approximation, i.e. setting $\bm{\rho}(t+1) = \bm{\rho}(t)$. Let us begin by expanding the summation:
\begin{equation}
\begin{split}
\bm{\rho}^m(t+1) &= \sum_{k=0}^{m} {m \choose k} (\mathbf{P} \circ \mathbf{R}^{m-k}) ^ T \bm{\rho}^k(t) =\\
&= \sum_{k=0}^{m-1} {m \choose k} (\mathbf{P} \circ \mathbf{R}^{m-k}) ^ T \bm{\rho}^k(t) +  {m \choose m} (\mathbf{P} \circ \mathbf{R}^{m-k}) ^ T \bm{\rho}^k(t) =\\
&=  \sum_{k=1}^{m-1} {m \choose k} (\mathbf{P} \circ \mathbf{R}^{m-k}) ^ T \bm{\rho}^k(t) +
     {m \choose m} (\mathbf{P} \circ \mathbf{R}^{0}) ^ T \bm{\rho}^m(t) +  {m \choose 0} (\mathbf{P} \circ \mathbf{R}^{m}) ^ T \bm{\rho}^0(t)
\end{split}
\end{equation}

then set $\bm{\rho}(t+1) = \bm{\rho}(t)$:
\begin{equation}
\begin{split}
\bm{\rho}^m(t) &=  \sum_{k=1}^{m-1} {m \choose k} (\mathbf{P} \circ \mathbf{R}^{m-k}) ^ T \bm{\rho}^k(t) +
     {m \choose m} (\mathbf{P} \circ \mathbf{R}^{0}) ^ T \bm{\rho}^m(t) +  {m \choose 0} (\mathbf{P} \circ \mathbf{R}^{m}) ^ T \bm{\rho}^0(t)
\end{split}
\end{equation}

simplify the binomial coefficients:
\begin{equation}
\begin{split}
\bm{\rho}^m(t) &=  \sum_{k=1}^{m-1} {m \choose k} (\mathbf{P} \circ \mathbf{R}^{m-k}) ^ T \bm{\rho}^k(t) +
     (\mathbf{P} \circ \mathbf{R}^{0}) ^ T \bm{\rho}^m(t) + (\mathbf{P} \circ \mathbf{R}^{m}) ^ T \bm{\rho}^0(t)
\end{split}
\end{equation}

further simplify since $\bm{\rho}^0(t) = \bm{1}$ and $\mathbf{R}^0 = \big ([1]\big)$ (as their entries are all raised to $0$):
\begin{equation}\label{mom}
\begin{split}
     \bm{\rho}^m(t) &= 
     \sum_{k=1}^{m-1} {m \choose k} (\mathbf{P} \circ \mathbf{R}^{m-k}) ^ T \bm{\rho}^k(t) +
     \mathbf{P} ^ T \bm{\rho}^m(t) + (\mathbf{P} \circ \mathbf{R}^{m}) ^ T \bm{1}
\end{split}
    \end{equation}
solve for $\bm{\rho}^m(t)$:    
\begin{equation}
\begin{split}
     \bm{\rho}^m(t) - \mathbf{P} ^ T \bm{\rho}^m(t) &= 
     \sum_{k=1}^{m-1} {m \choose k} (\mathbf{P} \circ \mathbf{R}^{m-k}) ^ T \bm{\rho}^k(t)
     + (\mathbf{P} \circ \mathbf{R}^{m}) ^ T \bm{1}\\
     ( \mathbf{I} - \mathbf{P}^T)  \bm{\rho}^m(t) &= 
     \sum_{k=1}^{m-1} {m \choose k} (\mathbf{P} \circ \mathbf{R}^{m-k}) ^ T \bm{\rho}^k(t)
     + (\mathbf{P} \circ \mathbf{R}^{m}) ^ T \bm{1} = 
\end{split}
    \end{equation}

The matrix $( \mathbf{I} - \mathbf{P}^T)$ is singular since the entries of the first column of $\mathbf{P}^T$ are all zeros. This is due to the fact that we are using an age-classified model in which individuals either grow older, and transit to the subsequent age class, or die every period $t$. Recalling the simple example of a Markov chain with three age classes:
\begin{equation}
    \mathbf{P}= \begin{pmatrix}
    0 & 0 & 0 & 0\\
    u_{12} & 0 & 0& 0\\
0 & u_{23} & u_{33}& 0\\
m_{14} & m_{24} & m_{34}& 1\\
    \end{pmatrix}
\end{equation}
and transposing:
\begin{equation}
    \mathbf{P}^T= \begin{pmatrix}
    0 &  u_{12} & 0 & m_{14}\\
    0 & 0 & u_{23} & m_{24}\\
    0 & 0 & u_{33} & m_{34}\\
    0 & 0 & 0 &1\\
    \end{pmatrix}
\end{equation}
we see that the matrix $\mathbf{P}^T$ has a full column of zeros, which makes it singular.
Therefore, it is not possible to compute its inverse and find a solution for $ \bm{\rho}^m(t) $ directly. Nevertheless, in some situations, we are eventually interested in the sub-vector $\Tilde{\bm{\rho}^m}(t)$, which collects the rewards of transient states, and we do not really care about the whole vector $ \bm{\rho}^m(t) $. 
For instance, when dealing with computation of healthy life expectancy, it is reasonable to assume that individuals stop accumulating rewards, i.e. years of life, when they are dead. This implies that the entries of the $ \bm{\rho}^m(t) $  vector  corresponding to the absorbing state (e.g $\mathds{E}(\rho_\alpha^k)) $ will all be zero. Thus, we really only care about the subvector  $\Tilde{\bm{\rho}^m}$ that collects the moments of accumulated rewards during transient states. This is, for example, the approach adopted by \cite{Caswell2018}. \\
The vector $\Tilde{\bm{\rho}^m}$ can be obtained by pre-multiplying the  $ \bm{\rho}^m(t) $ by a matrix $\mathbf{Z}$:
\begin{equation}
    \Tilde{\bm{\rho}}^k = \mathbf{Z}\bm{\rho}^k
\end{equation}
where $\mathbf{Z}$ is given by:
\begin{equation}
\mathbf{Z}=
    \begin{bmatrix}
    \mathbf{I} | \mathbf{0}
    \end{bmatrix}
\end{equation}
with $\mathbf{I}$ being an identity matrix (i.e. a square matrix with entries on the main diagonal equal to one and zeros elsewhere)  of dimension $(s \times s) $ and $\mathbf{0}$ being a matrix of zeros of dimension $(s \times 1) $.
To make an example, if $s = 4$,  $\bm{\rho}^k(t)$ will be:
\begin{equation}
\bm{\rho}^k(t) =
\begin{bmatrix}
E[\rho^k_1]\\
E[\rho^k_2]\\
E[\rho^k_{3}]\\
E[\rho^k_{4}]\\
\end{bmatrix}
\end{equation}
and $\mathbf{Z}$:
\begin{equation}
\mathbf{Z}=
    \begin{bmatrix}
   1 & 0 & 0 & 0\\
    0 & 1 & 0 & 0\\
     0 & 0 & 1 & 0\\
    \end{bmatrix}
\end{equation}
so that:
\begin{equation}
\Tilde{\bm{\rho}}^k(t) =
    \begin{bmatrix}
   1 & 0 & 0 & 0\\
    0 & 1 & 0 & 0\\
     0 & 0 & 1 & 0\\
    \end{bmatrix}
    \begin{bmatrix}
E[\rho^k_1]\\
E[\rho^k_2]\\
E[\rho^k_{3}]\\
E[\rho^k_{4}]\\
\end{bmatrix} = 
\begin{bmatrix}
E[\rho^k_1]\\
E[\rho^k_2]\\
E[\rho^k_{3}]\\
\end{bmatrix}
\end{equation}


Applying this reasoning to Equation \ref{mom}, we obtain:
\begin{equation}\label{mom2}
\begin{split}
     \mathbf{Z}\bm{\rho}^m(t) &= \mathbf{Z} \Bigg[ 
     \sum_{k=1}^{m-1} {m \choose k} (\mathbf{P} \circ \mathbf{R}^{m-k}) ^ T \bm{\rho}^k(t) +
     \mathbf{P} ^ T \bm{\rho}^m(t) + (\mathbf{P} \circ \mathbf{R}^{m}) ^ T \bm{1}\Bigg] = \\
     \Tilde{\bm{\rho}^m} &= \sum_{k=1}^{m-1} {m \choose k}\mathbf{Z}  (\mathbf{P} \circ \mathbf{R}^{m-k}) ^ T\mathbf{Z}^T \Tilde{\bm{\rho}}^k(t) + \mathbf{Z} \mathbf{P}^T \mathbf{Z}^T \Tilde{\bm{\rho}^m}  + \mathbf{Z} (\mathbf{P} \circ \mathbf{R}^{m}) ^ T \bm{1}
\end{split}
    \end{equation}
    
    
Note that $\mathbf{Z} \mathbf{P}^T \mathbf{Z}^T = \mathbf{U}^T $ and $ \mathbf{Z} (\mathbf{P} \circ \mathbf{R}^{m-k})\mathbf{Z}^T  = (\mathbf{U} \circ \Tilde{\mathbf{R}}^{m-k}) ^T $. For a simple example, see section \ref{sec:examples} below. Applying this additional simplification, we get:
\begin{equation}\label{mom2}
\begin{split}
     \Tilde{\bm{\rho}^m} &= \sum_{k=1}^{m-1} {m \choose k}(\mathbf{U} \circ \Tilde{\mathbf{R}}^{m-k}) ^T \Tilde{\bm{\rho}}^k(t) + \mathbf{U}^T \Tilde{\bm{\rho}^m}  + \mathbf{Z} (\mathbf{P} \circ \mathbf{R}^{m}) ^ T \bm{1}\\
     \Tilde{\bm{\rho}^m} -\mathbf{U}^T \Tilde{\bm{\rho}^m} &= \sum_{k=1}^{m-1} {m \choose k}(\mathbf{U} \circ \Tilde{\mathbf{R}}^{m-k}) ^T \Tilde{\bm{\rho}}^k(t) + \mathbf{Z} (\mathbf{P} \circ \mathbf{R}^{m}) ^ T \bm{1}  \\
     (\mathbf{I} - \mathbf{U}) \Tilde{\bm{\rho}^m} &= \sum_{k=1}^{m-1} {m \choose k}(\mathbf{U} \circ \Tilde{\mathbf{R}}^{m-k}) ^T \Tilde{\bm{\rho}}^k(t) + \mathbf{Z} (\mathbf{P} \circ \mathbf{R}^{m}) ^ T \bm{1}  \\
     \Tilde{\bm{\rho}^m} &= (\mathbf{I} - \mathbf{U})^{-1} \Bigg[ \sum_{k=1}^{m-1} {m \choose k}(\mathbf{U} \circ \Tilde{\mathbf{R}}^{m-k}) ^T \Tilde{\bm{\rho}}^k(t) + \mathbf{Z} (\mathbf{P} \circ \mathbf{R}^{m}) ^ T \bm{1} \Bigg]
\end{split}
    \end{equation}

It can be proved that \citep{Caswell2009}:
\begin{equation}
    (\mathbf{I} - \mathbf{U})^{-1} = \sum_{t=0}^\infty \mathbf{U}^t = \big( \mathds{E} (\nu_{ij}) \big) = \mathbf{N}
\end{equation}

Thus, we finally obtain:
\begin{equation}
     \Tilde{\bm{\rho}^m} = \mathbf{N}^T\mathbf{Z} (\mathbf{P} \circ \mathbf{R}_m)^T \bm{1}_s + \sum_{k=1}^{m-1} \binom{m}{k} \mathbf{N}^T \big( \mathbf{U} \circ \Tilde{\mathbf{R}}_{m-k})^T  \Tilde{\bm{\rho}}^k 
\end{equation}
which is the general formula mentioned in section \ref{sec:backward_solution}.\\

The matrix $\mathbf{N}$ is called the \lq\lq fundamental matrix'' of the Markov Chain and collects the expected number of visits to each transient state over the lifetime, i.e. the $\mathds{E} (\nu_{ij})$.  
Indeed, the entries of the matrix $\mathbf{U}$ represent the probability of
visiting any transient state after one time step; the entries of the matrix $\mathbf{U}^2$ collect the probabilities of visiting any transient state after two-time steps, and so on. If we were to add the powers of $\mathbf{U}$, we will end up with the expected number of visits to each transient state \citep{Caswell2009}. Note that when individuals transition every year, the expected number of visits will be equal to the time spent in a particular condition.\\

\tocless\subsection{Example}\label{sec:examples}
\begin{equation}
\begin{split}
    \mathbf{Z} \mathbf{P}^T \mathbf{Z}^T &=
    \begin{bmatrix}
   1 & 0 & 0 & 0\\
    0 & 1 & 0 & 0\\
     0 & 0 & 1 & 0\\
    \end{bmatrix}
    \begin{pmatrix}
    0 &  u_{12} & 0 & m_{14}\\
    0 & 0 & u_{23} & m_{24}\\
    0 & 0 & u_{33} & m_{34}\\
    0 & 0 & 0 &1\\
    \end{pmatrix}
    \begin{bmatrix}
    1 & 0 & 0\\
    0 & 1& 0\\
    0 & 0 & 1\\
    0 & 0 & 0\\
    \end{bmatrix}
    = \\
    &= \begin{bmatrix}
    0 & u_{12} & 0 & m_{14}\\
    0 & 0 & u_{23} & m_{24}\\
    0 & 0 & u_{23} & m_{24}\\
    \end{bmatrix}
    \begin{bmatrix}
    1 & 0 & 0\\
    0 & 1& 0\\
    0 & 0 & 1\\
    0 & 0 & 0\\
    \end{bmatrix} = \\
    &= 
    \begin{bmatrix}
    0 & u_{12} & 0\\
    0 & 0 & u_{23}\\
    0 & 0 & u_{33}
    \end{bmatrix} =
    \mathbf{U}^T
    \end{split}
\end{equation}


 \begin{equation}
     \begin{split}
          & \mathbf{Z} (\mathbf{P} \circ \mathbf{R}^{m-k})\mathbf{Z}^T = \\
          &=
     \begin{bmatrix}
   1 & 0 & 0 & 0\\
    0 & 1 & 0 & 0\\
     0 & 0 & 1 & 0\\
    \end{bmatrix}
    \Bigg(
    \begin{bmatrix}
    0 & 0 & 0 & 0\\
    u_{12} & 0 & 0& 0\\
0 & u_{23} & u_{33}& 0\\
m_{14} & m_{24} & m_{34}& 1\\
    \end{bmatrix}
    \circ 
    \begin{bmatrix}
  E[r^{m-k}_{11}]  &  E[r^{m-k}_{21}]  &E[r^{m-k}_{31}]  & E[r^{m-k}_{41}] \\
  E[r^{m-k}_{12}]  &  E[r^{m-k}_{22}]  &E[r^{m-k}_{32}]  & E[r^{m-k}_{42}] \\
  E[r^{m-k}_{13}]  &  E[r^{m-k}_{23}]  &E[r^{m-k}_{33}]  & E[r^{m-k}_{43}] \\
    E[r^{m-k}_{14}]  &  E[r^{m-k}_{24}]  &E[r^{m-k}_{34}]  & E[r^{m-k}_{44}] \\
 \end{bmatrix}
 \Bigg)
       \begin{bmatrix}
    1 & 0 & 0\\
    0 & 1& 0\\
    0 & 0 & 1\\
    0 & 0 & 0\\
    \end{bmatrix} =\\
    &=
     \begin{bmatrix}
   1 & 0 & 0 & 0\\
    0 & 1 & 0 & 0\\
     0 & 0 & 1 & 0\\
    \end{bmatrix}
    \Bigg(
    \begin{bmatrix}
    0 & 0 & 0 & 0\\
    u_{12}E[r^{m-k}_{12}] & 0 & 0 & 0\\
    0 & u_{23}E[r^{m-k}_{23}] & u_{33}E[r^{m-k}_{33}] & 0\\
    m_{14} E[r^{m-k}_{14}] & m_{24}E[r^{m-k}_{24}] & m_{34}E[r^{m-k}_{34}] & E[r^{m-k}_{44}]\\
    \end{bmatrix} 
     \Bigg)
       \begin{bmatrix}
    1 & 0 & 0\\
    0 & 1& 0\\
    0 & 0 & 1\\
    0 & 0 & 0\\
    \end{bmatrix} =\\
    &=
    \begin{bmatrix}
    0 & 0 & 0 & 0\\
    u_{12}E[r^{m-k}_{12}] & 0 & 0 & 0\\
    0 & u_{23}E[r^{m-k}_{23}] & u_{33}E[r^{m-k}_{33}] & 0
    \end{bmatrix}
    \begin{bmatrix}
    1 & 0 & 0\\
    0 & 1& 0\\
    0 & 0 & 1\\
    0 & 0 & 0\\
    \end{bmatrix} =\\
    &=
    \begin{bmatrix}
    0 & 0 &0\\
    u_{12}E[r^{m-k}_{12}] & 0 & 0\\
    0 & u_{23}E[r^{m-k}_{23}] & u_{33}E[r^{m-k}_{33}]
    \end{bmatrix} =\\
    &=
    \begin{bmatrix}
     0 & 0 &0\\
    u_{12} & 0 & 0\\
    0 & u_{23}& u_{33}\\
    \end{bmatrix}
    \circ
    \begin{bmatrix}
     E[r^{m-k}_{11}]& E[r^{m-k}_{13}] &E[r^{m-k}_{13}]\\
   E[r^{m-k}_{12}] & E[r^{m-k}_{23}]& E[r^{m-k}_{23}]\\
     E[r^{m-k}_{13}] & E[r^{m-k}_{33}] & E[r^{m-k}_{33}]\\
    \end{bmatrix} = (\mathbf{U}\circ \Tilde{\mathbf{R}}_{m-k})
     \end{split}
 \end{equation}






\begin{newpage}




\subfile{sections/empirical_analysis/7.results_full}



\chapter{Source code}


\section{Data cleaning and set up}



\subfile{sections/codes/data_manager}


\newpage

\section{Healthy and unhealthy longevity}



\subfile{sections/codes/estimates}


\end{newpage}
\end{document}